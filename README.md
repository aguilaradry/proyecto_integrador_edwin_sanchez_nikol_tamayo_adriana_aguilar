## proyecto_integrador_edwin_sanchez_nikol_tamayo_adriana_aguilar

## Proyecto de Ingesta de Datos desde una API a SQLite

### DescripciÃ³n del Proyecto  

Este proyecto automatiza la extracciÃ³n, almacenamiento y validaciÃ³n de datos desde la API [Sample APIs - Nintendo Switch Games](https://api.sampleapis.com/switch/games) hacia una base de datos SQLite, generando ademÃ¡s archivos de auditorÃ­a y evidencia en Excel. Todo el desarrollo se realizÃ³ en **GitHub Codespaces**.

La automatizaciÃ³n se realiza mediante **GitHub Actions**, garantizando que los datos se actualicen sin intervenciÃ³n manual.  


### MetodologÃ­a de Desarrollo  

#### **ExtracciÃ³n de Datos desde el API**  
- Se seleccionÃ³ la API de videojuegos de Nintendo Switch.
- Se creÃ³ un script en Python para consumir la API usando `requests`.  
- Se procesaron los datos extraÃ­dos asegurando su correcta estructura. 

#### **Almacenamiento en Base de Datos SQLite**  
- Se creÃ³ una base de datos en `src/bigdata/static/db/ingestion.db`.
- Se diseÃ±Ã³ un esquema con una tabla `videojuegos` para almacenar los datos.
- Se insertaron los datos extraÃ­dos de la API en la base de datos.

#### **GeneraciÃ³n de Evidencias**  
- **Archivo Excel**: Se usa `pandas` para exportar los datos a `ingestion.xlsx`.  
- **Archivo de AuditorÃ­a**: Se compara la cantidad de registros obtenidos de la API y los almacenados en la base de datos. 

#### **AutomatizaciÃ³n con GitHub Actions**  
- Se configurÃ³ un **workflow** que ejecuta la extracciÃ³n, almacenamiento y generaciÃ³n de evidencias automÃ¡ticamente.  
- Se verifica que la base de datos y los archivos generados sean correctos.  


### ðŸ“‚ Estructura del Proyecto  

[proyecto_integrador_edwin_sanchez_nikol_tamayo_adriana_aguilar]
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â”œâ”€â”€ .github
â”‚   â””â”€â”€ workflows
â”‚       â””â”€â”€ test_actividad1.yml
â””â”€â”€ src
    â”œâ”€â”€ static
    â”‚   â”œâ”€â”€ auditoria
    â”‚   â”‚   â””â”€â”€ ingestion.txt
    â”‚   â”œâ”€â”€ db
    â”‚   â”‚   â””â”€â”€ ingestion.db
    â”‚   â””â”€â”€ xlsx
    â”‚       â””â”€â”€ ingestion.xlsx
    â””â”€â”€ ingestion.py

### **AutomatizaciÃ³n con GitHub Actions**
El proyecto usa GitHub Actions para ejecutar la ingesta de datos automÃ¡ticamente.
Srchivo: .github/workflows/test_actividad1.yml
- Se crea un entorno virtual (python -m venv venv)
- Se activa el entorno virtual (./venv/Scripts/activate )
- Se actualiza pip (pip install --upgrade pip)
- InstalaciÃ³n de dependencias (pip install -e .)
- EjecuciÃ³n del script (python src/bigdata/ingestion.py)
- Commit y push de los cambios

### **TecnologÃ­as Utilizadas**
- Python (Requests, SQLite3, Pandas, OpenPyXL)
- GitHub Codespaces (para desarrollo en la nube)
- GitHub Actions (para la automatizaciÃ³n del proceso)
- SQLite (como base de datos para almacenamiento)

Este proyecto permite la extracciÃ³n y almacenamiento de datos de videojuegos de Nintendo Switch de manera estructurada y automatizada. Gracias a Codespaces, todo el desarrollo se realizÃ³ en la nube sin necesidad de configuraciones locales. AdemÃ¡s, la integraciÃ³n con GitHub Actions garantiza la ejecuciÃ³n automÃ¡tica y reproducible del proceso.

## Actividad 2: Preprocesamiento y Limpieza de Datos en Plataforma de Big Data en la Nube

### DescripciÃ³n
En esta actividad, se llevÃ³ a cabo un anÃ¡lisis exploratorio de datos (EDA) utilizando Pandas y SQLite, con el objetivo de identificar problemas de calidad en los datos. Posteriormente, se aplicaron tÃ©cnicas de limpieza para corregir estos problemas y almacenr los datos limpios en un archivo de formato CSV.

### Objetivos

- Cargar los datos desde una base SQLite.
- Realizar un anÃ¡lisis exploratorio para identificar:
    - Registros duplicados
    - Valores nulos
    - Inconsistencias en tipos de datos
- Introducir errores en los datos para simular problemas de calidad.
- Aplicar tÃ©cnicas de limpieza de datos para corregir los problemas detectados.
- Generar un informe de auditorÃ­a con los cambios realizados.
- Configurar un workflow en GitHub Actions para integrar el script de preprocesamiento y limpieza 

### AnÃ¡lisis Exploratorio
Se identificaron los siguientes problemas en los datos:
- Duplicados â†’ Se introdujeron 10 registros duplicados y se eliminaron en la limpieza.
- Valores nulos â†’ Se detectaron valores nulos en la columna "desarrolladores", que fueron reemplazados por "Desconocido".
- Errores en nombres â†’ Se limpiaron nombres eliminando caracteres especiales como #.
- Formato de fechas â†’ Se convirtieron a formato YYYY-MM-DD.
- ConversiÃ³n de fechas (valores vacÃ­os se reemplazan con la fecha actual)

### TÃ©cnicas de Limpieza Aplicadas
- EliminaciÃ³n de duplicados
- ImputaciÃ³n de valores nulos
- NormalizaciÃ³n de nombres y gÃ©neros
- CorrecciÃ³n de formato en las fechas
- Transformaciones en los tipos de datos

### Reportes Generados
- exploratory_analysis.txt â†’ AnÃ¡lisis de los datos antes de la limpieza
- cleaning_report.txt â†’ Transformaciones aplicadas en la limpieza
- cleaned_data.csv â†’ Datos limpios listos para su uso

### ðŸ“‚ Estructura del proyecto despuÃ©s de la actividad 2
.github/workflows/
â”‚â”€â”€ test_actividad1.yml              # Archivo de configuraciÃ³n para CI/CD
src/bigdata/
â”‚â”€â”€ static/
â”‚   â”œâ”€â”€ auditoria/                   # Carpeta de reportes de auditorÃ­a
â”‚   â”‚   â”œâ”€â”€ cleaning_report.txt      # Registro de la limpieza de datos
â”‚   â”‚   â”œâ”€â”€ exploratory_analysis.txt # AnÃ¡lisis exploratorio previo a la limpieza
â”‚   â”‚   â”œâ”€â”€ ingestion.txt            # Registro de la ingesta de datos
â”‚   â”œâ”€â”€ csv/                         # Datos en formato CSV
â”‚   â”‚   â”œâ”€â”€ cleaned_data.csv         # Datos despuÃ©s de la limpieza
â”‚   â”‚   â”œâ”€â”€ dirty_data.csv           # Datos con errores introducidos para pruebas
â”‚   â”œâ”€â”€ db/                          # Base de datos SQLite
â”‚   â”‚   â”œâ”€â”€ ingestion.db             # Archivo de la base de datos
â”‚   â”œâ”€â”€ xlsx/                        # Datos en formato Excel
â”‚   â”‚   â”œâ”€â”€ ingestion.xlsx           # Archivo Excel con los datos crudos
â”‚â”€â”€ cleaning.py                      # Script para la limpieza de datos
â”‚â”€â”€ ingestion.py                     # Script para la ingestiÃ³n de datos
â”‚â”€â”€ .gitignore                       # Archivos ignorados por Git
â”‚â”€â”€ README.md                        # DocumentaciÃ³n del proyecto
â”‚â”€â”€ setup.py                         # ConfiguraciÃ³n del entorno y dependencias


## Actividad 3: Enriquecimiento de Datos en Plataforma de Big Data en la Nube

### DescripciÃ³n
En esta actividad, su objetivo principal es implementar la etapa de enriquecimiento de datos a partir del dataset limpio generado en la Actividad 2.
El proceso consiste en integrar informaciÃ³n adicional proveniente de diferentes fuentes para complementar el conjunto de datos base y asÃ­ mejorar su calidad y valor analÃ­tico.

### Objetivos

- Cargar el conjunto de datos limpio generado previamente.
- Integrar informaciÃ³n adicional desde archivos en diversos formatos (CSV, JSON, XLSX, TXT, XML, HTML), 
  se escogiÃ³ el formato CSV
- Generar un archivo enriquecido y un reporte de auditorÃ­a que documenten el proceso.
- Automatizar el proceso utilizando GitHub Actions.

### DescripciÃ³n del Proceso
El script enrichment.py realiza las siguientes tareas:
- Carga de Datasets:
    - Lee el archivo cleaned_data.csv generado en la Actividad 2.
    - Lee el archivo adicional additional_data.csv con informaciÃ³n complementaria.
- Enriquecimiento:
    - Combina ambos datasets a travÃ©s de un cruce horizontal (pd.merge) utilizando la columna id como clave.
    - Agrega las columnas: plataforma, calificacion, tamano_gb.
- Guardado de Resultados:
    - Guarda el dataset enriquecido en: src/csv/enriched_data.csv.
- GeneraciÃ³n de AuditorÃ­a:
    - Crea un reporte enriched_report.txt que contiene: cantidad de registros coincidentes, registros que no encontraron informaciÃ³n adicional y transformaciones aplicadas.

### AutomatizaciÃ³n
Se incluye un Workflow de GitHub Actions ubicado en .github/workflows/test_actividad1.yml que:
- Ejecute el script de enriquecimiento automÃ¡ticamente cuando se sube cÃ³digo al repositorio.
- Genere como artefactos los archivos: enriched_data.csv y enriched_report.txt

### ðŸ“‚ Estructura del proyecto despuÃ©s de la actividad 3

[proyecto_integrador_edwin_sanchez_nikol_tamayo_adriana_aguilar]
â”œâ”€â”€ .github
â”‚   â””â”€â”€ workflows
â”‚       â””â”€â”€ test_actividad1.yml             # Workflow para la ingesta, limpieza y enriquecimiento
â”œâ”€â”€ src
â”‚   â””â”€â”€ bigdata
â”‚       â”œâ”€â”€ static
â”‚       â”‚   â”œâ”€â”€ auditoria
â”‚       â”‚   â”‚   â”œâ”€â”€ cleaning_report.txt    # Reporte de limpieza
â”‚       â”‚   â”‚   â”œâ”€â”€ exploratory_analysis.txt
â”‚       â”‚   â”‚   â”œâ”€â”€ ingestion.txt
â”‚       â”‚   â”‚   â””â”€â”€ enrichment_report.txt  # Reporte de auditorÃ­a del enriquecimiento
â”‚       â”‚   â”œâ”€â”€ csv
â”‚       â”‚   â”‚   â”œâ”€â”€ cleaned_data.csv       # Datos limpios
â”‚       â”‚   â”‚   â”œâ”€â”€ dirty_data.csv         # Datos originales
â”‚       â”‚   â”‚   â”œâ”€â”€ additional_info.csv    # Datos adicionales para enriquecer
â”‚       â”‚   â”‚   â””â”€â”€ enriched_data.csv      # Dataset enriquecido
â”‚       â”‚   â”œâ”€â”€ db
â”‚       â”‚   â”‚   â””â”€â”€ ingestion.db
â”‚       â”‚   â””â”€â”€ xlsx
â”‚       â”‚       â””â”€â”€ ingestion.xlsx
â”‚       â”œâ”€â”€ cleaning.py                    # Script de limpieza de datos
â”‚       â”œâ”€â”€ enrichment.py                  # Script de enriquecimiento de datos
â”‚       â””â”€â”€ ingestion.py                   # Script de ingesta de datos
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ setup.py